{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "* Change input data (ex. train.txt) into CRF model input format (ex. train.data)\n",
    "    * CRF model input format (ex. train.data):\n",
    "        ```\n",
    "        肝 O\n",
    "        功 O\n",
    "        能 O\n",
    "        6 B-med_exam\n",
    "        8 I-med_exam\n",
    "        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='data/SampleData_deid.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path2='data/development_2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadInputFile(path):\n",
    "    trainingset = list()  # store trainingset [content,content,...]\n",
    "    position = list()  # store position [article_id, start_pos, end_pos, entity_text, entity_type, ...]\n",
    "    mentions = dict()  # store mentions[mention] = Type\n",
    "    with open(file_path, 'r', encoding='utf8') as f:\n",
    "        file_text=f.read().encode('utf-8').decode('utf-8-sig')\n",
    "    datas=file_text.split('\\n\\n--------------------\\n\\n')[:-1]\n",
    "    for data in datas:\n",
    "        data=data.split('\\n')\n",
    "        content=data[0]\n",
    "        trainingset.append(content)\n",
    "        annotations=data[1:]\n",
    "        for annot in annotations[1:]:\n",
    "            annot=annot.split('\\t') #annot= article_id, start_pos, end_pos, entity_text, entity_type\n",
    "            position.extend(annot)\n",
    "            mentions[annot[3]]=annot[4]\n",
    "    \n",
    "    return trainingset, position, mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRFFormatData(trainingset, position, path):\n",
    "    if (os.path.isfile(path)):\n",
    "        os.remove(path)\n",
    "    outputfile = open(path, 'a', encoding= 'utf-8')\n",
    "\n",
    "    # output file lines\n",
    "    count = 0 # annotation counts in each content\n",
    "    tagged = list()\n",
    "    for article_id in range(len(trainingset)):\n",
    "        trainingset_split = list(trainingset[article_id])\n",
    "        while '' or ' ' in trainingset_split:\n",
    "            if '' in trainingset_split:\n",
    "                trainingset_split.remove('')\n",
    "            else:\n",
    "                trainingset_split.remove(' ')\n",
    "        start_tmp = 0\n",
    "        for position_idx in range(0,len(position),5):\n",
    "            if int(position[position_idx]) == article_id:\n",
    "                count += 1\n",
    "                if count == 1:\n",
    "                    start_pos = int(position[position_idx+1])\n",
    "                    end_pos = int(position[position_idx+2])\n",
    "                    entity_type=position[position_idx+4]\n",
    "                    if start_pos == 0:\n",
    "                        token = list(trainingset[article_id][start_pos:end_pos])\n",
    "                        whole_token = trainingset[article_id][start_pos:end_pos]\n",
    "                        for token_idx in range(len(token)):\n",
    "                            if len(token[token_idx].replace(' ','')) == 0:\n",
    "                                continue\n",
    "                            # BIO states\n",
    "                            if token_idx == 0:\n",
    "                                label = 'B-'+entity_type\n",
    "                            else:\n",
    "                                label = 'I-'+entity_type\n",
    "                            \n",
    "                            output_str = token[token_idx] + ' ' + label + '\\n'\n",
    "                            outputfile.write(output_str)\n",
    "\n",
    "                    else:\n",
    "                        token = list(trainingset[article_id][0:start_pos])\n",
    "                        whole_token = trainingset[article_id][0:start_pos]\n",
    "                        for token_idx in range(len(token)):\n",
    "                            if len(token[token_idx].replace(' ','')) == 0:\n",
    "                                continue\n",
    "                            \n",
    "                            output_str = token[token_idx] + ' ' + 'O' + '\\n'\n",
    "                            outputfile.write(output_str)\n",
    "\n",
    "                        token = list(trainingset[article_id][start_pos:end_pos])\n",
    "                        whole_token = trainingset[article_id][start_pos:end_pos]\n",
    "                        for token_idx in range(len(token)):\n",
    "                            if len(token[token_idx].replace(' ','')) == 0:\n",
    "                                continue\n",
    "                            # BIO states\n",
    "                            if token[0] == '':\n",
    "                                if token_idx == 1:\n",
    "                                    label = 'B-'+entity_type\n",
    "                                else:\n",
    "                                    label = 'I-'+entity_type\n",
    "                            else:\n",
    "                                if token_idx == 0:\n",
    "                                    label = 'B-'+entity_type\n",
    "                                else:\n",
    "                                    label = 'I-'+entity_type\n",
    "\n",
    "                            output_str = token[token_idx] + ' ' + label + '\\n'\n",
    "                            outputfile.write(output_str)\n",
    "\n",
    "                    start_tmp = end_pos\n",
    "                else:\n",
    "                    start_pos = int(position[position_idx+1])\n",
    "                    end_pos = int(position[position_idx+2])\n",
    "                    entity_type=position[position_idx+4]\n",
    "                    if start_pos<start_tmp:\n",
    "                        continue\n",
    "                    else:\n",
    "                        token = list(trainingset[article_id][start_tmp:start_pos])\n",
    "                        whole_token = trainingset[article_id][start_tmp:start_pos]\n",
    "                        for token_idx in range(len(token)):\n",
    "                            if len(token[token_idx].replace(' ','')) == 0:\n",
    "                                continue\n",
    "                            output_str = token[token_idx] + ' ' + 'O' + '\\n'\n",
    "                            outputfile.write(output_str)\n",
    "\n",
    "                    token = list(trainingset[article_id][start_pos:end_pos])\n",
    "                    whole_token = trainingset[article_id][start_pos:end_pos]\n",
    "                    for token_idx in range(len(token)):\n",
    "                        if len(token[token_idx].replace(' ','')) == 0:\n",
    "                            continue\n",
    "                        # BIO states\n",
    "                        if token[0] == '':\n",
    "                            if token_idx == 1:\n",
    "                                label = 'B-'+entity_type\n",
    "                            else:\n",
    "                                label = 'I-'+entity_type\n",
    "                        else:\n",
    "                            if token_idx == 0:\n",
    "                                label = 'B-'+entity_type\n",
    "                            else:\n",
    "                                label = 'I-'+entity_type\n",
    "                        \n",
    "                        output_str = token[token_idx] + ' ' + label + '\\n'\n",
    "                        outputfile.write(output_str)\n",
    "                    start_tmp = end_pos\n",
    "\n",
    "        token = list(trainingset[article_id][start_tmp:])\n",
    "        whole_token = trainingset[article_id][start_tmp:]\n",
    "        for token_idx in range(len(token)):\n",
    "            if len(token[token_idx].replace(' ','')) == 0:\n",
    "                continue\n",
    "\n",
    "            \n",
    "            output_str = token[token_idx] + ' ' + 'O' + '\\n'\n",
    "            outputfile.write(output_str)\n",
    "\n",
    "        count = 0\n",
    "    \n",
    "        output_str = '\\n'\n",
    "        outputfile.write(output_str)\n",
    "        ID = trainingset[article_id]\n",
    "\n",
    "        if article_id%10 == 0:\n",
    "            print('Total complete articles:', article_id)\n",
    "\n",
    "    # close output file\n",
    "    outputfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset, position, mentions=loadInputFile(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total complete articles: 0\n",
      "Total complete articles: 10\n",
      "Total complete articles: 20\n"
     ]
    }
   ],
   "source": [
    "data_path='data/sample.data'\n",
    "CRFFormatData(trainingset, position, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER model\n",
    "### CRF (Conditional Random Field model)\n",
    "* Using `sklearn-crfsuite` API\n",
    "\n",
    "    (you may try `CRF++`, `python-crfsuite`, `pytorch-crfsuite`(neural network version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRF(x_train, y_train, x_test, y_test):\n",
    "    crf = sklearn_crfsuite.CRF(\n",
    "        algorithm='lbfgs',\n",
    "        c1=0.1,\n",
    "        c2=0.1,\n",
    "        max_iterations=100,\n",
    "        all_possible_transitions=True\n",
    "    )\n",
    "    crf.fit(x_train, y_train)\n",
    "    # print(crf)\n",
    "    y_pred = crf.predict(x_test)\n",
    "    y_pred_mar = crf.predict_marginals(x_test)\n",
    "\n",
    "    # print(y_pred_mar)\n",
    "\n",
    "    labels = list(crf.classes_)\n",
    "    labels.remove('O')\n",
    "    f1score = metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels)\n",
    "    sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0])) # group B and I results\n",
    "    print(flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))\n",
    "    return y_pred, y_pred_mar, f1score, crf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Input: \n",
    "* input features:\n",
    "    * word vector: pretrained traditional chinese word embedding by Word2Vec-CBOW\n",
    "    \n",
    "    (you may try add some other features, ex. pos-tag, word_length, word_position, ...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained word vectors\n",
    "# get a dict of tokens (key) and their pretrained word vectors (value)\n",
    "# pretrained word2vec CBOW word vector: https://fgc.stpi.narl.org.tw/activity/videoDetail/4b1141305ddf5522015de5479f4701b1\n",
    "dim = 0\n",
    "word_vecs= {}\n",
    "# open pretrained word vector file\n",
    "with open('cna.cbow.cwe_p.tar_g.512d.0.txt',encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        tokens = line.strip().split()\n",
    "\n",
    "        # there 2 integers in the first line: vocabulary_size, word_vector_dim\n",
    "        if len(tokens) == 2:\n",
    "            dim = int(tokens[1])\n",
    "            continue\n",
    "    \n",
    "        word = tokens[0] \n",
    "        vec = np.array([ float(t) for t in tokens[1:] ])\n",
    "        word_vecs[word] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary_size:  158566  word_vector_dim:  (512,)\n"
     ]
    }
   ],
   "source": [
    "print('vocabulary_size: ',len(word_vecs),' word_vector_dim: ',vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split data into training dataset and testing dataset,\n",
    "however, we'll provide `development data` and `test data` which is real testing dataset.\n",
    "\n",
    "You should upload prediction on `development data` and `test data` to system, not this splitted testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load `train.data` and separate into a list of labeled data of each text\n",
    "# return:\n",
    "#   data_list: a list of lists of tuples, storing tokens and labels (wrapped in tuple) of each text in `train.data`\n",
    "#   traindata_list: a list of lists, storing training data_list splitted from data_list\n",
    "#   testdata_list: a list of lists, storing testing data_list splitted from data_list\n",
    "from sklearn.model_selection import train_test_split\n",
    "def Dataset(data_path):\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        data=f.readlines()#.encode('utf-8').decode('utf-8-sig')\n",
    "    data_list, data_list_tmp = list(), list()\n",
    "    article_id_list=list()\n",
    "    idx=0\n",
    "    for row in data:\n",
    "        data_tuple = tuple()\n",
    "        if row == '\\n':\n",
    "            article_id_list.append(idx)\n",
    "            idx+=1\n",
    "            data_list.append(data_list_tmp)\n",
    "            data_list_tmp = []\n",
    "        else:\n",
    "            row = row.strip('\\n').split(' ')\n",
    "            data_tuple = (row[0], row[1])\n",
    "            data_list_tmp.append(data_tuple)\n",
    "    if len(data_list_tmp) != 0:\n",
    "        data_list.append(data_list_tmp)\n",
    "    \n",
    "    # here we random split data into training dataset and testing dataset\n",
    "    # but you should take `development data` or `test data` as testing data\n",
    "    # At that time, you could just delete this line, \n",
    "    # and generate data_list of `train data` and data_list of `development/test data` by this function\n",
    "    traindata_list, testdata_list, traindata_article_id_list, testdata_article_id_list=train_test_split(data_list,\n",
    "                                                                                                    article_id_list,\n",
    "                                                                                                    test_size=0.5,\n",
    "                                                                                                    random_state=42)\n",
    "    \n",
    "    return data_list, traindata_list, testdata_list, traindata_article_id_list, testdata_article_id_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up word vectors\n",
    "# turn each word into its pretrained word vector\n",
    "# return a list of word vectors corresponding to each token in train.data\n",
    "def Word2Vector(data_list, embedding_dict, dim):\n",
    "    embedding_list = list()\n",
    "\n",
    "    # No Match Word (unknown word) Vector in Embedding\n",
    "    unk_vector=np.random.rand(*(list(embedding_dict.values())[0].shape))\n",
    "\n",
    "    for idx_list in range(len(data_list)):\n",
    "        embedding_list_tmp = list()\n",
    "        for idx_tuple in range(len(data_list[idx_list])):\n",
    "            key = data_list[idx_list][idx_tuple][0] # token\n",
    "\n",
    "            if key in embedding_dict:\n",
    "                value = embedding_dict[key]\n",
    "            else:\n",
    "                value = unk_vector\n",
    "            embedding_list_tmp.append(value[0:dim])\n",
    "        embedding_list.append(embedding_list_tmp)\n",
    "    return embedding_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input features: pretrained word vectors of each token\n",
    "# return a list of feature dicts, each feature dict corresponding to each token\n",
    "def Feature(embed_list):\n",
    "    feature_list = list()\n",
    "    for idx_list in range(len(embed_list)):\n",
    "        feature_list_tmp = list()\n",
    "        for idx_tuple in range(len(embed_list[idx_list])):\n",
    "            feature_dict = dict()\n",
    "            for idx_vec in range(len(embed_list[idx_list][idx_tuple])):\n",
    "                feature_dict['dim_' + str(idx_vec+1)] = embed_list[idx_list][idx_tuple][idx_vec]\n",
    "            feature_list_tmp.append(feature_dict)\n",
    "        feature_list.append(feature_list_tmp)\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the labels of each tokens in train.data\n",
    "# return a list of lists of labels\n",
    "def Preprocess(data_list):\n",
    "    label_list = list()\n",
    "    for idx_list in range(len(data_list)):\n",
    "        label_list_tmp = list()\n",
    "        for idx_tuple in range(len(data_list[idx_list])):\n",
    "            label_list_tmp.append(data_list[idx_list][idx_tuple][1])\n",
    "        label_list.append(label_list_tmp)\n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list, traindata_list, testdata_list, traindata_article_id_list, testdata_article_id_list = Dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Word Embedding\n",
    "trainembed_list = Word2Vector(traindata_list, word_vecs, dim)\n",
    "testembed_list = Word2Vector(testdata_list, word_vecs, dim)\n",
    "\n",
    "# CRF - Train Data (Augmentation Data)\n",
    "x_train = Feature(trainembed_list)\n",
    "y_train = Preprocess(traindata_list)\n",
    "\n",
    "# CRF - Test Data (Golden Standard)\n",
    "x_test = Feature(testembed_list)\n",
    "y_test = Preprocess(testdata_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALEX\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass labels=['B-location', 'I-location', 'B-med_exam', 'I-med_exam', 'B-money', 'I-money', 'B-name', 'I-name', 'B-time', 'I-time'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-location      0.000     0.000     0.000        23\n",
      "  I-location      0.000     0.000     0.000        59\n",
      "  B-med_exam      0.000     0.000     0.000        46\n",
      "  I-med_exam      1.000     0.019     0.037       107\n",
      "     B-money      0.364     0.333     0.348        12\n",
      "     I-money      0.444     0.343     0.387        35\n",
      "      B-name      0.111     0.143     0.125         7\n",
      "      I-name      0.333     0.100     0.154        10\n",
      "      B-time      0.519     0.403     0.454       134\n",
      "      I-time      0.721     0.455     0.558       319\n",
      "\n",
      "   micro avg      0.607     0.291     0.394       752\n",
      "   macro avg      0.349     0.180     0.206       752\n",
      "weighted avg      0.573     0.291     0.349       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_pred_mar, f1score, crf = CRF(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34943209577955175"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploadtest_data_id = []  # store trainingset [content,content,...]\n",
    "uploadtest_data_text = []\n",
    "\n",
    "with open(file_path2, 'r', encoding='utf8') as f:\n",
    "    file_text = f.read().encode('utf-8').decode('utf-8-sig')\n",
    "datas = file_text.split('\\n\\n--------------------\\n\\n')[:-1]\n",
    "for data in datas:\n",
    "    data = data.split('\\n')\n",
    "    uploadtest_data_id.append(data[0][12:])\n",
    "    uploadtest_data_text.append(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_list = Word2Vector(uploadtest_data_text, word_vecs, dim)\n",
    "# CRF - Test Data (Golden Standard)\n",
    "x_test_upload = Feature(testing_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-location      0.000     0.000     0.000        23\n",
      "  I-location      0.000     0.000     0.000        59\n",
      "  B-med_exam      0.000     0.000     0.000        46\n",
      "  I-med_exam      1.000     0.019     0.037       107\n",
      "     B-money      0.364     0.333     0.348        12\n",
      "     I-money      0.444     0.343     0.387        35\n",
      "      B-name      0.111     0.143     0.125         7\n",
      "      I-name      0.333     0.100     0.154        10\n",
      "      B-time      0.519     0.403     0.454       134\n",
      "      I-time      0.721     0.455     0.558       319\n",
      "\n",
      "   micro avg      0.607     0.291     0.394       752\n",
      "   macro avg      0.349     0.180     0.206       752\n",
      "weighted avg      0.573     0.291     0.349       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_upload = crf.predict(x_test_upload)\n",
    "\n",
    "# print(y_pred_mar)\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "f1score = metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels)\n",
    "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0])) # group B and I results\n",
    "print(flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34943209577955175"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output data\n",
    "* Change model output into `output.tsv` \n",
    "* Only accept this output format uploading to competition system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_id\tstart_position\tend_position\tentity_text\tentity_type\n",
      "0\t3306\t3309\t3天份\ttime\n",
      "1\t457\t459\t五月\ttime\n",
      "1\t671\t674\t三個月\ttime\n",
      "2\t40\t45\t上上個禮拜\ttime\n",
      "2\t722\t724\t焦距\ttime\n",
      "2\t752\t755\t一點點\ttime\n",
      "2\t1096\t1098\t半年\ttime\n",
      "2\t1114\t1116\t半年\ttime\n",
      "2\t1118\t1120\t半年\ttime\n",
      "2\t1147\t1150\t三個月\ttime\n",
      "2\t1227\t1231\t兩個禮拜\ttime\n",
      "2\t1464\t1467\t一點點\ttime\n",
      "3\t84\t86\t爬樓\tlocation\n",
      "3\t150\t152\t爬樓\tlocation\n",
      "3\t576\t580\t6月4號\ttime\n",
      "3\t582\t584\t前年\ttime\n",
      "3\t592\t594\t前年\ttime\n",
      "3\t915\t917\t分鐘\ttime\n",
      "3\t1882\t1884\t去年\ttime\n",
      "3\t1929\t1931\t四月\ttime\n",
      "3\t1932\t1934\t五月\ttime\n",
      "3\t2033\t2036\t8月份\ttime\n",
      "3\t2178\t2180\t八月\ttime\n",
      "3\t2195\t2197\t八月\ttime\n",
      "3\t2204\t2207\t八月份\ttime\n",
      "3\t2230\t2233\t八月份\ttime\n",
      "3\t3131\t3133\t明天\ttime\n",
      "4\t161\t164\t一點點\ttime\n",
      "4\t187\t190\t林醫師\tname\n",
      "4\t354\t358\t上個禮拜\ttime\n",
      "4\t731\t734\t林醫師\tname\n",
      "4\t806\t809\t林醫師\tname\n",
      "4\t815\t818\t林醫師\tname\n",
      "4\t844\t847\t林醫師\tname\n",
      "4\t880\t883\t林醫師\tname\n",
      "4\t958\t960\t小姐\tname\n",
      "4\t1606\t1609\t林醫師\tname\n",
      "4\t1620\t1623\t林醫師\tname\n",
      "4\t1665\t1668\t林醫師\tname\n",
      "4\t1811\t1814\t林醫師\tname\n",
      "4\t1960\t1963\t三個月\ttime\n",
      "4\t1967\t1970\t三個月\ttime\n",
      "4\t1974\t1977\t三個月\ttime\n",
      "4\t1979\t1982\t三個月\ttime\n",
      "4\t1988\t1991\t三個月\ttime\n",
      "5\t88\t90\t八點\ttime\n",
      "5\t478\t480\t圓圓\tname\n",
      "5\t485\t487\t圓圓\tname\n",
      "5\t863\t866\t6公分\tmed_exam\n",
      "5\t1047\t1051\t昨天晚上\ttime\n",
      "5\t1919\t1921\t上午\ttime\n",
      "5\t1927\t1929\t上午\ttime\n",
      "5\t2163\t2165\t註明\tname\n",
      "5\t2437\t2441\t6月6號\ttime\n",
      "5\t2476\t2478\t兩點\ttime\n",
      "5\t2486\t2488\t早點\ttime\n",
      "6\t28\t32\t上個禮拜\ttime\n",
      "6\t86\t88\t前年\ttime\n",
      "6\t376\t380\t7月4號\ttime\n",
      "6\t519\t522\t水太太\tname\n",
      "6\t802\t805\t三四天\ttime\n",
      "6\t822\t825\t三四天\ttime\n",
      "6\t829\t832\t三四天\ttime\n",
      "6\t895\t899\t兩個禮拜\ttime\n",
      "6\t1091\t1093\t小姐\tname\n",
      "6\t1625\t1627\t櫻木\tname\n",
      "7\t717\t719\t三百\tmoney\n",
      "7\t889\t892\t三個月\ttime\n",
      "7\t910\t913\t三個月\ttime\n",
      "7\t1038\t1041\t三個月\ttime\n",
      "7\t1045\t1048\t三個月\ttime\n",
      "8\t215\t218\t黃醫師\tname\n",
      "8\t262\t265\t黃醫師\tname\n",
      "8\t533\t536\t黃醫師\tname\n",
      "8\t685\t689\t兩個禮拜\ttime\n",
      "8\t764\t767\t黃醫師\tname\n",
      "9\t35\t37\t五月\ttime\n",
      "9\t357\t359\t個公\tmed_exam\n",
      "9\t419\t421\t公斤\tmoney\n",
      "9\t419\t432\t公斤記一下，那你身高幾公分\tmoney\n",
      "10\t63\t65\t公斤\tmoney\n",
      "10\t241\t245\t兩個禮拜\ttime\n",
      "10\t262\t266\t四個禮拜\ttime\n",
      "10\t414\t416\t圓圓\tname\n",
      "10\t472\t476\t四個禮拜\ttime\n",
      "10\t537\t541\t十月六號\ttime\n",
      "11\t26\t29\t上禮拜\ttime\n",
      "11\t82\t85\t一份資\ttime\n",
      "11\t132\t135\t林醫師\tname\n",
      "11\t143\t146\t林醫師\tname\n",
      "11\t154\t156\t紐約\tlocation\n",
      "11\t174\t176\t紐約\tlocation\n",
      "11\t210\t213\t林醫師\tname\n",
      "11\t313\t316\t林醫師\tname\n",
      "11\t455\t458\t林醫師\tname\n",
      "11\t513\t516\t林醫師\tname\n",
      "11\t592\t594\t兩年\ttime\n",
      "11\t676\t678\t紐約\tlocation\n",
      "11\t729\t732\t三個月\ttime\n",
      "11\t763\t766\t四個月\ttime\n",
      "11\t815\t819\t邁丁半顆\ttime\n",
      "11\t827\t831\t邁丁半顆\ttime\n",
      "11\t930\t933\t林醫師\tname\n",
      "11\t1094\t1097\t林醫師\tname\n",
      "11\t1153\t1156\t兩個月\ttime\n",
      "11\t1179\t1182\t兩個月\ttime\n",
      "11\t1184\t1186\t前天\ttime\n",
      "11\t1196\t1198\t前天\ttime\n",
      "11\t1233\t1236\t兩個月\ttime\n",
      "11\t1238\t1241\t兩個月\ttime\n",
      "11\t1273\t1276\t兩個月\ttime\n",
      "11\t1353\t1355\t紐約\tlocation\n",
      "11\t1358\t1360\t紐約\tlocation\n",
      "11\t1416\t1419\t兩個月\ttime\n",
      "11\t1470\t1472\t紐約\tlocation\n",
      "11\t1636\t1638\t後年\ttime\n",
      "11\t1647\t1649\t兩年\ttime\n",
      "11\t1653\t1655\t後年\ttime\n",
      "11\t1662\t1664\t後年\ttime\n",
      "11\t1869\t1872\t林醫師\tname\n",
      "11\t1888\t1890\t去年\ttime\n",
      "11\t2029\t2032\t林醫師\tname\n",
      "13\t48\t52\t9月2號\ttime\n",
      "13\t493\t496\t0月底\ttime\n",
      "13\t701\t704\t一點綠\ttime\n",
      "14\t1136\t1140\t前兩個月\ttime\n",
      "14\t1312\t1315\t一點點\ttime\n",
      "15\t632\t634\t前鎮\ttime\n",
      "16\t203\t207\t三個禮拜\ttime\n",
      "16\t218\t222\t六個禮拜\ttime\n",
      "16\t235\t239\t六個禮拜\ttime\n",
      "16\t257\t261\t六個禮拜\ttime\n",
      "16\t424\t427\t三個月\ttime\n",
      "16\t447\t449\t兩年\ttime\n",
      "17\t1567\t1569\t明天\ttime\n",
      "17\t1578\t1580\t明天\ttime\n",
      "17\t1593\t1595\t明天\ttime\n",
      "17\t1604\t1606\t明天\ttime\n",
      "17\t1611\t1616\t今天禮拜天\ttime\n",
      "17\t1621\t1626\t今天禮拜天\ttime\n",
      "17\t1692\t1694\t小花\tname\n",
      "17\t2026\t2028\t跨月\ttime\n",
      "17\t2034\t2036\t五月\ttime\n",
      "17\t2038\t2041\t五月份\ttime\n",
      "17\t2062\t2065\t六月份\ttime\n",
      "17\t2179\t2181\t七天\ttime\n",
      "17\t2344\t2346\t五月\ttime\n",
      "18\t21\t23\t五月\ttime\n",
      "18\t429\t432\t三個月\ttime\n",
      "18\t485\t487\t半年\ttime\n",
      "18\t485\t587\t半年一次檢查就好了。民眾：好。醫師：啊下次來就應該是打流感疫苗的時間了，我們再一起打好嗎？民眾：好啊。醫師：好齁。啊假如你有朋友或認識的人想要吃PrEP，也可以跟我們講一下。民眾：好。醫師：因為還有一些公\ttime\n",
      "19\t53\t55\t五次\ttime\n",
      "19\t371\t373\t去撞\ttime\n",
      "19\t382\t384\t去撞\ttime\n",
      "19\t829\t831\t直撞\tlocation\n",
      "19\t1812\t1814\t五次\ttime\n",
      "19\t2090\t2092\t四百\tmoney\n",
      "19\t2349\t2351\t去撞\ttime\n",
      "19\t2416\t2418\t直撞\tlocation\n",
      "19\t2419\t2421\t直撞\tlocation\n",
      "19\t3012\t3015\t在陽明\ttime\n",
      "19\t3081\t3084\t在陽明\ttime\n",
      "19\t3836\t3839\t去陽明\ttime\n",
      "19\t3868\t3871\t去陽明\ttime\n",
      "19\t4040\t4043\t五顆星\ttime\n",
      "19\t4098\t4104\t八天至十四天\ttime\n",
      "20\t944\t946\t能公\ttime\n",
      "20\t1011\t1013\t兩年\ttime\n",
      "20\t1307\t1313\t三個月三個月\ttime\n",
      "20\t1314\t1317\t三個月\ttime\n",
      "20\t3013\t3016\t三個月\ttime\n",
      "20\t3780\t3782\t證百\tmoney\n",
      "20\t4646\t4650\t8月2號\ttime\n",
      "21\t86\t88\t一份\ttime\n",
      "21\t209\t211\t一號\ttime\n",
      "21\t238\t240\t零號\ttime\n",
      "21\t293\t295\t一號\ttime\n",
      "21\t330\t332\t零號\ttime\n",
      "21\t377\t379\t零號\ttime\n",
      "21\t1947\t1949\t一百\tmoney\n",
      "21\t2030\t2032\t一百\tmoney\n",
      "21\t2044\t2046\t一百\tmoney\n",
      "22\t522\t525\t在陽明\ttime\n",
      "22\t981\t984\t四個月\ttime\n",
      "22\t989\t992\t四個月\ttime\n",
      "22\t1173\t1175\t承認\tname\n",
      "22\t2104\t2107\t三個月\ttime\n",
      "22\t2109\t2112\t六個月\ttime\n",
      "22\t2893\t2895\t七天\ttime\n",
      "22\t3040\t3042\t七天\ttime\n",
      "22\t3132\t3134\t七天\ttime\n",
      "22\t3183\t3185\t證明\ttime\n",
      "22\t3351\t3354\t三個月\ttime\n",
      "22\t3484\t3488\t一萬多塊\tmoney\n",
      "22\t3576\t3579\t三個月\ttime\n",
      "22\t3616\t3621\t早上和禮拜\ttime\n",
      "22\t3623\t3625\t下午\ttime\n",
      "22\t3832\t3834\t三份\ttime\n",
      "23\t1033\t1035\t八次\ttime\n",
      "24\t84\t87\t五六顆\ttime\n",
      "24\t94\t97\t五六顆\ttime\n",
      "24\t267\t270\t三四天\ttime\n",
      "24\t382\t384\t七天\ttime\n",
      "25\t1131\t1133\t五天\ttime\n",
      "25\t1196\t1198\t七顆\ttime\n",
      "25\t1222\t1225\t三四天\ttime\n",
      "26\t243\t245\t平日\tlocation\n",
      "26\t2339\t2342\t三個月\ttime\n",
      "26\t2542\t2545\t三個月\ttime\n",
      "26\t2569\t2572\t林小姐\tname\n",
      "27\t264\t267\t中七天\ttime\n",
      "27\t355\t358\t上個月\ttime\n",
      "28\t1161\t1163\t前天\ttime\n",
      "28\t1161\t2145\t前天有一個個案問我說有沒有案例是吃了PrEP之後他還是被感染的？民眾：對。個管師：目前來說我們去釐清了一些原因，有一些是說他吃了PrEP。民眾：他不正……個管師：比如說我知道你吃了PrEP……民眾：吃法不正確？個管師：但是你不正確阿。民眾：恩恩恩。個管師：那你沒有具保護力。民眾：恩恩。個管師：可是在網……網路上就會傳說阿這個人有吃PrEP……民眾：恩。個管師：但是還是被感染，其實並不是。民眾：恩恩。個管師：是他並沒有正確的吃，但是唯一……唯一的這麼多例裡面就唯一有一個……民眾：恩。個管師：他是好好的吃。民眾：恩。個管師：但是還是被感染了，那其中我們去……去研究的原因是因為他真的遇到一個抗藥性很強的病毒。民眾：剛好有突變的嗎？個管師：抗藥性很強。民眾：可以說那個病毒也突變……個管師：也不算突變，就是它的，它具有抗藥性阿。民眾：恩恩恩。個管師：所以你身上的病毒，誒，你身上的藥的濃度沒有辦法殺死這個病毒。民眾：恩。個管師：所以他還是會感染，所以為什麼才會說保險套其實是目前來說比較，誒，兩個一起使用的話感染的機率真的會比較小。民眾：恩，可是因為他就只防在，通常也不會就全程配戴，就是在開始的，像口交那一些的，有些也不會戴阿。個管師：恩，口交的部分，就69的部分其實有時候阿，有時候……民眾：恩。個管師：恩，目前來說精液裡面的比較少，就是一些分泌物比較少。民眾：恩哼哼，恩。個管師：但不代表他沒有。民眾：恩。個管師：但是說最大量的就是在精液裡面。民眾：恩。個管師：對，最大量的在精液裡面。民眾：恩。個管師：然後體液裡面會比較少量。民眾：恩。個管師：對阿，那你說，因為摩擦或口交會不會有？民眾：恩。個管師：我們就看兩個層面嘛，有些人就說為什麼我……我聽說誰誰誰口交也……也被傳染了？民眾：恩恩恩。個管師：好，那就是第一個，他可能嘴巴有傷口。民眾：恩。個管師：然後再來就是口爆在嘴裡面，就是這樣。民眾：喔喔喔，恩。個管師：對，所以他就是大量的病毒，然後又剛好又有傷口。民眾：如果是在其他的部位，皮膜的也會有可能？個管師：很少阿。民眾：恩哼哼。個管師：對很少，就是機……機率阿，機率近乎於零，但不等於零。民眾：恩恩。個管師：因為其實只要是人都會有很多的不可抗，就是沒有辦法預測的因素。民眾：恩。個管師：對，比如說，好，一起喝，一起吃飯，比如說夾，同桌夾菜然後可能沒有用公\ttime\n",
      "29\t256\t259\t三個月\ttime\n",
      "29\t380\t383\t三個月\ttime\n",
      "29\t559\t562\t三個月\ttime\n",
      "29\t1443\t1446\t三個月\ttime\n",
      "29\t1527\t1530\t三個月\ttime\n",
      "29\t1872\t1875\t的月份\ttime\n",
      "29\t2023\t2030\t一個月7月6號\ttime\n",
      "29\t2325\t2328\t三個月\ttime\n",
      "29\t2569\t2571\t兩份\ttime\n",
      "30\t444\t448\t今天禮拜\ttime\n",
      "30\t469\t472\t禮拜日\ttime\n",
      "30\t510\t513\t禮拜日\ttime\n",
      "30\t525\t528\t禮拜日\ttime\n",
      "30\t690\t695\t三個時間點\ttime\n",
      "30\t725\t728\t時間點\ttime\n",
      "30\t875\t881\t三顆的時間點\ttime\n",
      "30\t1629\t1631\t半年\ttime\n",
      "31\t1924\t1928\t8月3號\ttime\n",
      "31\t2012\t2015\t三個月\ttime\n",
      "32\t594\t596\t明天\ttime\n",
      "32\t798\t801\t時間點\ttime\n",
      "32\t818\t821\t時間點\ttime\n",
      "32\t827\t829\t八點\ttime\n",
      "32\t862\t864\t八點\ttime\n",
      "32\t949\t951\t八點\ttime\n",
      "32\t959\t961\t三點\ttime\n",
      "32\t1208\t1210\t小美\tname\n",
      "32\t1308\t1311\t三個月\ttime\n",
      "32\t1312\t1315\t六個月\ttime\n",
      "32\t1348\t1351\t三個月\ttime\n",
      "32\t1433\t1436\t三個月\ttime\n",
      "32\t1444\t1447\t五千塊\tmoney\n",
      "32\t1458\t1460\t四千\tmoney\n",
      "32\t1461\t1463\t五千\tmoney\n",
      "32\t1857\t1859\t：公\tmed_exam\n",
      "32\t1911\t1913\t：公\tmed_exam\n",
      "32\t1911\t1925\t：公費是多少？醫師：沒有啊公\tmed_exam\n",
      "32\t1950\t1952\t五百\tmoney\n",
      "32\t2198\t2201\t三個月\ttime\n",
      "32\t2211\t2214\t三個月\ttime\n",
      "32\t2239\t2241\t半年\ttime\n",
      "32\t2312\t2315\t三個月\ttime\n",
      "32\t2408\t2411\t三個月\ttime\n",
      "32\t2668\t2671\t三個月\ttime\n",
      "33\t55\t57\t下午\ttime\n",
      "33\t881\t885\t0月7號\ttime\n",
      "33\t916\t919\t二早上\ttime\n",
      "33\t921\t923\t下午\ttime\n",
      "34\t437\t439\t五年\ttime\n",
      "34\t513\t515\t半年\ttime\n",
      "34\t667\t672\t一點點小小\ttime\n",
      "34\t724\t726\t半年\ttime\n",
      "34\t732\t734\t半年\ttime\n",
      "34\t772\t775\t五個月\ttime\n",
      "34\t779\t782\t五個月\ttime\n",
      "34\t2830\t2832\t半年\ttime\n",
      "34\t2874\t2877\t三個月\ttime\n",
      "34\t2903\t2905\t月份\ttime\n",
      "34\t4279\t4281\t下午\ttime\n",
      "34\t4296\t4298\t下午\ttime\n",
      "34\t4418\t4420\t下午\ttime\n",
      "35\t168\t171\t陳小姐\ttime\n",
      "35\t221\t224\t陳小姐\ttime\n",
      "35\t1444\t1446\t證明\ttime\n",
      "35\t1913\t1916\t一點點\ttime\n",
      "35\t2084\t2087\t間千萬\tmoney\n",
      "35\t2110\t2112\t兩點\ttime\n",
      "35\t2143\t2145\t兩點\ttime\n",
      "35\t2169\t2171\t技巧\ttime\n",
      "35\t3218\t3220\t證百\tmoney\n",
      "35\t3397\t3399\t半年\ttime\n",
      "35\t3480\t3482\t半年\ttime\n",
      "35\t3486\t3489\t三個月\ttime\n",
      "35\t3504\t3507\t上半年\ttime\n",
      "35\t4149\t4151\t證明\ttime\n",
      "35\t4696\t4698\t七八\ttime\n",
      "35\t4727\t4729\t早期\ttime\n",
      "36\t17\t20\t六點半\ttime\n",
      "36\t28\t31\t六點半\ttime\n",
      "36\t43\t46\t七點四\ttime\n",
      "36\t74\t76\t下午\ttime\n",
      "36\t291\t293\t明天\ttime\n",
      "36\t586\t590\t第七個月\ttime\n",
      "36\t602\t604\t半年\ttime\n",
      "36\t660\t662\t四月\ttime\n",
      "36\t678\t680\t四月\ttime\n",
      "36\t715\t717\t四月\ttime\n",
      "36\t801\t803\t早點\ttime\n",
      "37\t1069\t1071\t4千\tmoney\n",
      "37\t1073\t1075\t5千\tmoney\n",
      "38\t115\t117\t七天\ttime\n",
      "38\t141\t143\t八號\ttime\n",
      "38\t160\t164\t兩個禮拜\ttime\n",
      "38\t423\t425\t七天\ttime\n",
      "39\t141\t144\t三個月\ttime\n",
      "39\t770\t773\t六個月\ttime\n",
      "39\t1717\t1720\t三個月\ttime\n",
      "39\t2008\t2011\t六個月\ttime\n",
      "40\t561\t563\t半年\ttime\n",
      "40\t662\t664\t半年\ttime\n",
      "40\t855\t858\t兩年期\ttime\n",
      "41\t1079\t1081\t前路\ttime\n",
      "41\t1667\t1669\t早點\ttime\n",
      "41\t1674\t1676\t早點\ttime\n",
      "41\t1684\t1686\t早點\ttime\n",
      "41\t1905\t1908\t三個月\ttime\n",
      "42\t571\t574\t一點圓\ttime\n",
      "42\t675\t678\t黃醫師\tname\n",
      "42\t679\t684\t黃明明醫師\tname\n",
      "42\t688\t693\t黃明明醫師\tname\n",
      "42\t2359\t2361\t脈搏\tlocation\n",
      "42\t2566\t2568\t脈搏\tlocation\n",
      "42\t2649\t2651\t脈搏\tlocation\n",
      "43\t152\t154\t：公\tmed_exam\n",
      "43\t209\t211\t半年\ttime\n",
      "43\t213\t216\t三個月\ttime\n",
      "43\t220\t222\t半年\ttime\n",
      "43\t229\t231\t明天\ttime\n",
      "43\t287\t291\t兩個禮拜\ttime\n",
      "43\t287\t376\t兩個禮拜來一次這樣子。民眾：因為我找工作他們都跟我說那我這幾個月可能要請假這樣子，他說要常請假，我說要回診看。醫師：阿不然就，這，那個就好，我幫你寫一張這樣子喔。民眾：對啊，那公\ttime\n",
      "43\t395\t397\t證明\ttime\n",
      "43\t400\t402\t市公\tmed_exam\n",
      "43\t435\t438\t一點點\ttime\n",
      "43\t443\t445\t公斤\tmoney\n",
      "43\t565\t567\t中午\ttime\n",
      "43\t702\t704\t下午\ttime\n",
      "43\t819\t823\t兩個禮拜\ttime\n",
      "43\t862\t866\t兩個禮拜\ttime\n",
      "43\t939\t947\t早上兩顆晚上兩顆\ttime\n",
      "43\t983\t987\t早上兩顆\ttime\n",
      "43\t1109\t1117\t早上兩顆晚上兩顆\ttime\n",
      "43\t1175\t1179\t兩個禮拜\ttime\n",
      "43\t1560\t1563\t三個月\ttime\n",
      "44\t501\t504\t一點點\ttime\n",
      "44\t710\t714\t兩個禮拜\ttime\n",
      "45\t244\t247\t橡樹葉\ttime\n",
      "45\t477\t480\t兩個月\ttime\n",
      "45\t485\t488\t兩個月\ttime\n",
      "45\t517\t520\t二個月\ttime\n",
      "45\t627\t630\t9月初\ttime\n",
      "45\t634\t637\t8月初\ttime\n",
      "45\t640\t643\t9月底\ttime\n",
      "45\t646\t649\t兩個月\ttime\n",
      "45\t665\t668\t兩個月\ttime\n",
      "45\t678\t681\t兩個月\ttime\n",
      "45\t1153\t1156\t兩個月\ttime\n",
      "45\t1254\t1257\t兩個月\ttime\n",
      "46\t216\t219\t三天多\ttime\n",
      "46\t274\t278\t上個禮拜\ttime\n",
      "46\t297\t300\t後禮拜\ttime\n",
      "46\t469\t471\t下午\ttime\n",
      "46\t521\t523\t下午\ttime\n",
      "46\t613\t615\t下午\ttime\n",
      "46\t726\t728\t下午\ttime\n",
      "46\t799\t801\t時鐘\ttime\n",
      "46\t1313\t1315\t七八\ttime\n",
      "46\t1409\t1412\t一點點\ttime\n",
      "46\t2485\t2489\t三個禮拜\ttime\n",
      "46\t2485\t3220\t三個禮拜。民眾：不會拖這麼久。醫師：對不會拖這麼久。民眾：因為我一回去上班其實我的時間就很長。然後變成我的休息時間又縮短了。醫師：嗯嗯。啊要輪夜班嘛？民眾：呃，應該之後工作性質會稍微調整一下，應該是先不輪班吧。不然這樣下去我覺得我的身體好不了。醫師：嗯嗯。民眾：對。醫師：不過這個是會好的。就是慢慢會調整回來。民眾：就是讓自己免疫系統恢復到正常就好。醫師：對對。民眾：OK，所以我這種症狀基本上因為有巨細胞病毒那種已經有抗體了嗎？看不出來。醫師：呃……我看一下。民眾：因為其實我還是怕會傳染給小朋友。醫師：嗯……民眾：所以我在家，其實我沒吃藥那陣子我還是沒戴口罩，但是溫度拉起來之後我又開始戴口罩，我在想說我到底要不要戴口罩帶小朋友。醫師：我看一下喔。我應該幫你驗一下，之後。這理論上都會有抗體啦，就是保護性抗體。民眾：喔，暸解，已經好一陣子應該要有抗體就對了。醫師：對，要有抗體起來了。我看一下。幫你驗一下好了。民眾：你說今天加驗，下次再看？醫師：下次再驗就好了啦。民眾：那醫生有一個那個，我看那個上次你印報告給我，我看那個B型肝炎的抗體，那個是大於10還是小於10啊？因為我看那個數字……醫師：我看一下喔。B肝嗎？民眾：對。醫師：134。民眾：134。那可是那是，可是他單位是小於10，害我，他的參考建議值是小於10，那我以為我那個，可是我去對我自己的檢查報告，我那是寫大於等於10，所以我就不懂這裡是小於10……醫師：沒有你要看，這個是正常，這個是參考檢驗區，啊你是有136你是有保護力的。民眾：喔是有保護力的。醫師：對，這個是好的意思啊。民眾：這是好的意思。醫師：就是你已經有產生免疫抗體了。民眾：喔。醫師：所以你不會被B型肝炎病毒感染。民眾：了解。醫師：你們公\ttime\n",
      "46\t3857\t3861\t兩個禮拜\ttime\n",
      "46\t3870\t3874\t兩個禮拜\ttime\n",
      "46\t3889\t3893\t兩個禮拜\ttime\n",
      "46\t3922\t3925\t上禮拜\ttime\n",
      "46\t4003\t4007\t兩個禮拜\ttime\n",
      "46\t4410\t4412\t證明\ttime\n",
      "46\t4929\t4932\t三個月\ttime\n",
      "46\t5085\t5087\t證明\ttime\n",
      "47\t303\t306\t林醫師\tname\n",
      "48\t13\t15\t小明\tname\n",
      "48\t571\t574\t一點點\ttime\n",
      "48\t647\t650\t兩個月\ttime\n",
      "48\t655\t658\t兩個月\ttime\n",
      "48\t659\t662\t兩個月\ttime\n",
      "48\t847\t849\t小明\tname\n",
      "48\t1475\t1477\t去撞\ttime\n",
      "48\t1759\t1762\t兩個月\ttime\n",
      "48\t1794\t1796\t。公\tmed_exam\n",
      "49\t91\t93\t小美\tname\n",
      "49\t160\t162\t小美\tname\n",
      "49\t548\t552\t一點時間\ttime\n",
      "49\t560\t564\t一點時間\ttime\n",
      "49\t842\t844\t分鐘\ttime\n",
      "49\t915\t917\t分鐘\ttime\n",
      "49\t961\t963\t小明\tname\n",
      "49\t990\t992\t下午\ttime\n",
      "49\t1172\t1174\t下午\ttime\n",
      "49\t1297\t1299\t下午\ttime\n",
      "49\t1862\t1864\t再巡\ttime\n",
      "49\t2116\t2119\t：公職\tmed_exam\n",
      "49\t2928\t2930\t小美\tname\n",
      "49\t3049\t3053\t9月8號\ttime\n",
      "49\t3923\t3926\t親姐姐\ttime\n",
      "49\t4579\t4582\t一點小\ttime\n",
      "49\t4778\t4780\t小美\tname\n",
      "50\t16\t18\t一份\ttime\n",
      "50\t125\t128\t禮拜天\ttime\n",
      "50\t138\t140\t前天\ttime\n",
      "50\t144\t146\t前天\ttime\n",
      "50\t151\t153\t前天\ttime\n",
      "50\t507\t510\t一點點\ttime\n",
      "50\t514\t517\t一點點\ttime\n",
      "50\t529\t532\t一點點\ttime\n",
      "50\t536\t539\t一點點\ttime\n",
      "50\t1057\t1059\t前天\ttime\n",
      "50\t1185\t1188\t…月底\ttime\n",
      "50\t1516\t1519\t去早上\ttime\n",
      "50\t3502\t3504\t新樓\tlocation\n",
      "51\t269\t273\t一張證明\ttime\n",
      "51\t459\t461\t證明\ttime\n",
      "51\t839\t841\t證明\ttime\n",
      "51\t971\t973\t去撞\ttime\n",
      "51\t1100\t1102\t擦撞\tlocation\n",
      "51\t1263\t1266\t1月份\ttime\n",
      "51\t1283\t1286\t1月份\ttime\n",
      "51\t1660\t1662\t證明\ttime\n",
      "51\t1676\t1678\t半年\ttime\n",
      "51\t1727\t1729\t證明\ttime\n",
      "51\t1773\t1775\t證明\ttime\n",
      "51\t2039\t2043\t三個禮拜\ttime\n",
      "51\t2052\t2056\t三個禮拜\ttime\n",
      "51\t2061\t2066\t前兩個禮拜\ttime\n",
      "51\t2094\t2098\t三個禮拜\ttime\n",
      "51\t2858\t2860\t公斤\tmoney\n",
      "51\t2868\t2870\t公斤\tmoney\n",
      "51\t2884\t2886\t公斤\tmoney\n",
      "51\t3289\t3292\t上禮拜\ttime\n",
      "51\t3790\t3792\t公斤\tmoney\n",
      "51\t4366\t4368\t明天\ttime\n",
      "51\t4396\t4398\t明天\ttime\n",
      "51\t4552\t4556\t三個禮拜\ttime\n",
      "51\t4566\t4570\t兩個禮拜\ttime\n",
      "51\t4573\t4577\t兩個禮拜\ttime\n",
      "51\t4685\t4687\t證明\ttime\n",
      "51\t4830\t4832\t公斤\tmoney\n",
      "51\t4849\t4851\t公斤\tmoney\n",
      "51\t4860\t4862\t公斤\tmoney\n",
      "51\t4860\t4882\t公斤。家屬：對阿，真的我就很頭痛阿，阿他阿公\tmoney\n",
      "51\t4860\t5195\t公斤。家屬：對阿，真的我就很頭痛阿，阿他阿公……醫師：對阿，因為這陣子也是覺得有點納悶就是，欸？怎麼越吃越……人就越來越……家屬：對阿，他就全身無力。醫師：越來越消瘦。家屬：對，他全身無力然後就沒辦法吃，真的沒辦法吃，沒辦法下嚥然後就這樣子很不舒服。醫師：這個藥對你來講很重要喔，我覺得。家屬：對阿，我…他也知道那個……民眾：我看那個藥上面副作用，也沒有這些副作用……醫師：沒有嘛。民眾：對阿，所以我才覺得奇怪為甚麼會這樣子。家屬：對，然後他也很認真吃。民眾：阿唯一的副作用就寫腹瀉阿，阿可是……醫師：你也沒有腹瀉。民眾：就偶爾就是因為脹氣太嚴重阿就是會腹瀉這樣子。醫師：喔。民眾：阿所以我也不知道到底是藥的關係，還是人本身的關係。家屬：然後就整個人這樣子軟趴趴的他阿公\tmoney\n",
      "51\t5209\t5211\t公年\ttime\n",
      "51\t5209\t5261\t公年紀大了，我們真的沒辦法再幫你了耶。因為我照顧他照顧到我都椎間盤突出，我都坐骨神經都發作了。然後他阿公\ttime\n",
      "51\t5209\t5510\t公年紀大了，我們真的沒辦法再幫你了耶。因為我照顧他照顧到我都椎間盤突出，我都坐骨神經都發作了。然後他阿公就說好我今天陪他來這看一下，看到底是怎樣，因為他真的已經……民眾：醫師那我想問一下，可以吃B群嗎？醫師：正常可以吃阿。家屬：然後我有用一些中藥保護胃腸的齁，我叫他隔開吃，可以嘛齁？因為中藥只是是保養的而已，因為看他這樣我真的很頭痛。醫師：你中藥先不要吃好不好。家屬：好阿。醫師：因為他現在吃藥還有在吃細菌的藥齁。家屬：好好好好。醫師：阿那個……家屬：好，可是他那個……醫師：容易強碰阿，西藥容易跟那些強碰。家屬：因為我就跟他差不多隔兩個小時吧，可是他就是沒辦法一直脹氣，一直脹氣脹到他一直吐，他阿公\ttime\n",
      "51\t5209\t5631\t公年紀大了，我們真的沒辦法再幫你了耶。因為我照顧他照顧到我都椎間盤突出，我都坐骨神經都發作了。然後他阿公就說好我今天陪他來這看一下，看到底是怎樣，因為他真的已經……民眾：醫師那我想問一下，可以吃B群嗎？醫師：正常可以吃阿。家屬：然後我有用一些中藥保護胃腸的齁，我叫他隔開吃，可以嘛齁？因為中藥只是是保養的而已，因為看他這樣我真的很頭痛。醫師：你中藥先不要吃好不好。家屬：好阿。醫師：因為他現在吃藥還有在吃細菌的藥齁。家屬：好好好好。醫師：阿那個……家屬：好，可是他那個……醫師：容易強碰阿，西藥容易跟那些強碰。家屬：因為我就跟他差不多隔兩個小時吧，可是他就是沒辦法一直脹氣，一直脹氣脹到他一直吐，他阿公看了真的很心痛阿。民眾：真的阿。家屬：這不知道該怎麼辦。醫師：我們就想辦法……看有沒有辦法兩全其美這樣子。家屬：對。醫師：我就寫2020年5月就持續每天治療，並且狀況仍不穩定這樣子。家屬：好好。醫師：好齁。家屬，好，好，謝謝。然後就是說他阿公\ttime\n",
      "51\t5856\t5858\t五天\ttime\n",
      "52\t244\t247\t一點點\ttime\n",
      "52\t251\t254\t一點點\ttime\n",
      "52\t332\t336\t兩個禮拜\ttime\n",
      "52\t397\t401\t兩個禮拜\ttime\n",
      "52\t526\t529\t林醫師\tname\n",
      "52\t541\t544\t林醫師\tname\n",
      "52\t703\t706\t林醫師\tname\n",
      "52\t1148\t1151\t，明明\tname\n",
      "52\t1271\t1273\t小美\tname\n",
      "52\t1280\t1284\t兩個禮拜\ttime\n",
      "52\t1391\t1395\t兩個禮拜\ttime\n",
      "53\t114\t118\t兩個禮拜\ttime\n",
      "53\t239\t242\t一點點\ttime\n",
      "53\t337\t341\t兩個禮拜\ttime\n",
      "53\t411\t413\t二號\ttime\n",
      "53\t439\t444\t六百七十九\tmoney\n",
      "53\t650\t652\t一千\tmoney\n",
      "54\t254\t256\t去年\ttime\n",
      "54\t568\t570\t二月\ttime\n",
      "55\t1043\t1045\t去年\ttime\n",
      "55\t1063\t1065\t去年\ttime\n",
      "55\t1109\t1111\t五月\ttime\n",
      "56\t27\t30\t：星期\ttime\n",
      "56\t27\t958\t：星期三回來的。醫師：阿出院後有比較好嗎？家屬：出院後喔。醫師：嗯。家屬：就是，每一次都這樣啊。醫師：這樣喔。家屬：就是回來然後回到家後就是，也是會吵著要去打針啦。醫師：打針喔。因為這次也是，那個心臟也是，稍微退化了阿。家屬：嗯。醫師：嘿，所以肺部有積水。家屬：阿住院的時候。醫師：嗯。家屬：是不是，我，我幫他，那個，移床位嘛。醫師：嘿。家屬：因為他都會往下滑，然後我叫他自己上來他上不來。醫師：上不來。家屬：啊我就拉他這邊，結果他說，他腰那邊很痛。醫師：很痛喔。家屬：說我把他拉傷了。醫師：阿現在。家屬：有沒有可能？醫師：應該不會欸，嘿啊。家屬：可是，他說是我把他拉傷的。醫師：這樣喔。家屬：然後都一直喊痛。醫師：我看你骨頭有，這有的說不定本來骨頭就比較退化，我來看看蛤。家屬：他說是腰這邊。醫師：腰喔。阿你之前去注射是因為腰痛還是？家屬：喔，全身都不舒服。醫師：全身都不舒服。家屬：你問他都說這樣啊。醫師：這樣喔。我在想下次我們可能要，也要。家屬：要抽血。醫師：就是。家屬：是嗎？醫師：因為腎臟功能。家屬：你上次有。醫師：對對，本來。家屬：你上次有開那個單阿。醫師：嗯。家屬：啊我們沒有沒有，來抽血。醫師：沒關係，因為住院就有檢查。阿你腰開過刀本來就，就退化後很嚴重阿。就以前開刀的地方。家屬：對對。醫師：然後側彎這樣子，嗯。喔，好。阿尿尿有沒有正常？家屬：今天好像要拔尿管。醫師：拔尿管齁，要解解看對不對？家屬：嗯。醫師：有辦法自己上廁所嗎？民眾：有喔。家屬：是有，可是他說排不乾淨，所以叫我們尿管，我們已經拔掉，那天出院的時候拔掉，然後。醫師：喔。家屬：又說。醫師：尿不乾淨。醫師：尿不乾淨又插回去。家屬：又給他重插。醫師：啊假如拔掉又尿不出來怎麼辦？家屬：是會尿得出來只是說他說尿不乾淨哪。醫師：喔，那幫他按摩一下這樣子，齁。家屬：那你們有個護理師為什麼叫我要學習怎麼導尿？醫師：導尿，那就要學那個技術，他有教你怎麼？家屬：沒有，他就教我去掛泌尿科。醫師：掛泌尿。家屬：在那邊學。醫師：會學喔。醫師：一般是住院的時候學，比較。家屬：沒有，那時候我們要掛泌尿科才會學。醫師：這樣齁。泌尿科你要來一次，我們先拔拔看這樣好不好？家屬：嗯。醫師：那我們就幫阿公\ttime\n",
      "56\t2152\t2154\t九月\ttime\n",
      "56\t2166\t2169\t兩個月\ttime\n",
      "56\t2177\t2179\t一號\ttime\n",
      "56\t2209\t2212\t五禮拜\ttime\n",
      "56\t2220\t2222\t下午\ttime\n",
      "56\t2300\t2302\t九天\ttime\n",
      "57\t49\t51\t五小\ttime\n",
      "57\t60\t63\t九個小\ttime\n",
      "57\t69\t72\t九個小\ttime\n",
      "57\t183\t186\t前兩天\ttime\n",
      "57\t386\t388\t公斤\tmoney\n",
      "57\t386\t434\t公斤？民眾：沒有量。醫師：沒有量齁，嘿，那我們量一下。民眾：八十五。醫師：八十五，阿你身高幾公分\tmoney\n",
      "57\t441\t444\t一七五\tmoney\n",
      "57\t448\t451\t一七五\tmoney\n",
      "57\t523\t525\t四年\ttime\n",
      "57\t531\t533\t四年\ttime\n",
      "57\t746\t750\t三個禮拜\ttime\n",
      "57\t753\t757\t四個禮拜\ttime\n",
      "57\t798\t802\t三個禮拜\ttime\n",
      "57\t1066\t1068\t一百\tmoney\n",
      "57\t1306\t1309\t五十歲\ttime\n",
      "57\t1790\t1793\t兩個月\ttime\n",
      "57\t1813\t1816\t五個月\ttime\n",
      "57\t1850\t1853\t五個月\ttime\n",
      "57\t1859\t1862\t五個月\ttime\n",
      "57\t1876\t1879\t五個月\ttime\n",
      "57\t1909\t1912\t五個月\ttime\n",
      "57\t2082\t2084\t二月\ttime\n",
      "58\t243\t246\t一點點\ttime\n",
      "58\t767\t770\t三個月\ttime\n",
      "59\t4\t7\t禮拜天\ttime\n",
      "59\t8\t10\t中午\ttime\n",
      "59\t21\t23\t中午\ttime\n",
      "59\t491\t494\t林醫師\tname\n",
      "59\t921\t923\t中午\ttime\n",
      "59\t1940\t1943\t在陽明\ttime\n",
      "60\t125\t127\t先搬\ttime\n",
      "60\t364\t367\t兩個月\ttime\n",
      "60\t521\t524\t8月底\ttime\n",
      "60\t547\t550\t8月底\ttime\n",
      "60\t1200\t1202\t下午\ttime\n",
      "60\t1210\t1212\t下午\ttime\n",
      "60\t1343\t1345\t下午\ttime\n",
      "60\t1360\t1362\t下午\ttime\n",
      "60\t1499\t1501\t小姐\tname\n",
      "60\t1540\t1543\t5月份\ttime\n",
      "60\t1787\t1789\t的號\ttime\n",
      "60\t1842\t1844\t小夫\tname\n",
      "60\t1849\t1851\t小夫\tname\n",
      "60\t1855\t1857\t小夫\tname\n",
      "60\t1922\t1925\t夫的夫\tlocation\n",
      "60\t1930\t1933\t夫的夫\tlocation\n",
      "60\t1967\t1969\t證英\ttime\n",
      "60\t2084\t2087\t6月底\ttime\n",
      "60\t2582\t2584\t三年\ttime\n",
      "60\t2600\t2602\t三年\ttime\n",
      "61\t541\t544\t二個月\ttime\n",
      "61\t868\t871\t一點點\ttime\n",
      "61\t882\t884\t斤斤\tmoney\n",
      "61\t890\t893\t時間點\ttime\n",
      "61\t899\t902\t時間點\ttime\n",
      "61\t957\t960\t時間點\ttime\n",
      "61\t1031\t1034\t時間點\ttime\n",
      "61\t1041\t1044\t時間點\ttime\n",
      "61\t1072\t1074\t八點\ttime\n",
      "61\t1083\t1085\t八點\ttime\n",
      "61\t1137\t1139\t八點\ttime\n",
      "61\t1143\t1145\t八點\ttime\n",
      "61\t1154\t1156\t八點\ttime\n",
      "61\t1176\t1179\t時間點\ttime\n",
      "61\t2030\t2033\t兩個月\ttime\n",
      "61\t2136\t2138\t平日\tlocation\n",
      "61\t2343\t2345\t五月\ttime\n",
      "61\t2388\t2390\t三百\tmoney\n",
      "62\t795\t799\t第十個月\ttime\n",
      "62\t919\t921\t下午\ttime\n",
      "63\t343\t347\t上上個月\ttime\n",
      "64\t9\t12\t兩個月\ttime\n",
      "64\t746\t749\t兩個月\ttime\n",
      "64\t782\t785\t兩個月\ttime\n",
      "64\t876\t880\t兩顆兩顆\ttime\n",
      "64\t1006\t1008\t三年\ttime\n",
      "64\t1057\t1059\t兩年\ttime\n",
      "65\t205\t208\t上個月\ttime\n",
      "65\t1415\t1417\t一號\ttime\n",
      "65\t1475\t1477\t一號\ttime\n",
      "66\t25\t27\t小明\tname\n",
      "66\t140\t142\t後哩\ttime\n",
      "66\t253\t255\t前天\ttime\n",
      "66\t269\t271\t前天\ttime\n",
      "67\t34\t37\t許小姐\ttime\n",
      "67\t61\t64\t許小姐\ttime\n",
      "67\t70\t72\t資格\tlocation\n",
      "67\t330\t333\t半年多\ttime\n",
      "67\t1113\t1116\t三個月\ttime\n",
      "67\t1137\t1140\t的月份\ttime\n",
      "67\t1244\t1250\t下午，禮拜五\ttime\n",
      "69\t266\t269\t等姐姐\ttime\n",
      "69\t1056\t1059\t前兩天\ttime\n",
      "69\t1597\t1601\t9月8號\ttime\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output=\"article_id\\tstart_position\\tend_position\\tentity_text\\tentity_type\\n\"\n",
    "for test_id in range(len(y_pred_upload)):\n",
    "    pos=0\n",
    "    start_pos=None\n",
    "    end_pos=None\n",
    "    entity_text=None\n",
    "    entity_type=None\n",
    "    for pred_id in range(len(y_pred_upload[test_id])):\n",
    "        if y_pred_upload[test_id][pred_id][0]=='B':\n",
    "            start_pos=pos\n",
    "            entity_type=y_pred_upload[test_id][pred_id][2:]\n",
    "        elif start_pos is not None and y_pred_upload[test_id][pred_id][0]=='I' and y_pred_upload[test_id][pred_id+1][0]=='O':\n",
    "            end_pos=pos\n",
    "            entity_text=''.join([uploadtest_data_text[test_id][position][0] for position in range(start_pos,end_pos+1)])\n",
    "            \n",
    "            line=str(uploadtest_data_id[test_id])+'\\t'\n",
    "            line=line+str(start_pos)+'\\t'\n",
    "            line=line+str(end_pos+1)+'\\t'\n",
    "            line=line+str(entity_text)+'\\t'\n",
    "            line=line+entity_type\n",
    "            output+=line+'\\n'\n",
    "        pos+=1     \n",
    "        \n",
    "output_path='output_1207_nonO.tsv'\n",
    "with open(output_path,'w',encoding='utf-8') as f:\n",
    "    f.write(output)\n",
    "    \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "* You may try `python-crfsuite` to train an neural network for NER tagging optimized by gradient descent back propagation\n",
    "    * [Documentation](https://github.com/scrapinghub/python-crfsuite)\n",
    "* You may try `CRF++` tool for NER tagging by CRF model\n",
    "    * [Documentation](http://taku910.github.io/crfpp/)\n",
    "    * Need design feature template\n",
    "    * Can only computed in CPU\n",
    "* You may try other traditional chinese word embedding (ex. fasttext, bert, ...) for input features\n",
    "* You may try add other features for NER model, ex. POS-tag, word_length, word_position, ...\n",
    "* You should upload the prediction output on `development data` or `test data` provided later to the competition system. Note don't upload prediction output on the splitted testing dataset like this baseline example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
